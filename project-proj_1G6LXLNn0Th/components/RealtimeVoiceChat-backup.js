function RealtimeVoiceChat({ onTranscript, onAIResponse, imageAnalysis, isProcessing, setIsProcessing, sessionId, onReady }) {
  try {
    const [isConnected, setIsConnected] = React.useState(false);
    const [isRecording, setIsRecording] = React.useState(false);
    const [isSpeaking, setIsSpeaking] = React.useState(false);
    const [connectionError, setConnectionError] = React.useState('');
    
    const clientRef = React.useRef(null);
    const wavRecorderRef = React.useRef(null);
    const wavPlayerRef = React.useRef(null);

    // é‡‡æ ·ç‡
    const sampleRate = 24000;

    // Initialize Realtime components
    React.useEffect(() => {
      if (!sessionId) {
        console.log('â³ ç­‰å¾…sessionId...');
        return;
      }

      const initializeRealtime = async () => {
        try {
          console.log('ğŸ¤ å¼€å§‹åˆå§‹åŒ–å®æ—¶è¯­éŸ³æœåŠ¡ï¼ŒsessionId:', sessionId);
          
          // æ£€æŸ¥å…¨å±€åº“æ˜¯å¦å·²åŠ è½½
          if (!window.RealtimeClient || !window.WavRecorder || !window.WavStreamPlayer) {
            throw new Error('å®æ—¶è¯­éŸ³åº“æœªåŠ è½½ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•');
          }

          const RealtimeClient = window.RealtimeClient;
          const WavRecorder = window.WavRecorder;
          const WavStreamPlayer = window.WavStreamPlayer;

          // æŒ‰ç…§Step-Realtime-Consoleçš„æ–¹å¼åˆå§‹åŒ–
          // WebSocketä»£ç†URLï¼ŒåŒ…å«sessionIdå‚æ•°
          let wsProxyUrl = `ws://localhost:8082?sessionId=${sessionId}&model=step-1o-audio`;
          
          console.log('ğŸ”— è¿æ¥WebSocketä»£ç†:', wsProxyUrl);
          
          // åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆè¿æ¥åˆ°ä½ çš„WebSocketä»£ç†æœåŠ¡å™¨ï¼‰
          clientRef.current = new RealtimeClient({ 
            url: wsProxyUrl,
            apiKey: 'dummy-key', // çœŸå®å¯†é’¥ç”±åç«¯ä»£ç†å¤„ç†
            dangerouslyAllowAPIKeyInBrowser: true,
            debug: true
          });

          // åˆå§‹åŒ–éŸ³é¢‘ç»„ä»¶
          wavRecorderRef.current = new WavRecorder({ 
            sampleRate: sampleRate 
          });
          
          wavPlayerRef.current = new WavStreamPlayer({ 
            sampleRate: sampleRate 
          });

          // è®¾ç½®äº‹ä»¶å¤„ç†å™¨
          setupEventHandlers();

          // åˆå§‹åŒ–éŸ³é¢‘ç»„ä»¶
          await wavRecorderRef.current.begin();
          await wavPlayerRef.current.connect();
          
          // è¿æ¥å®¢æˆ·ç«¯
          await clientRef.current.connect();
          
          console.log('âœ… å®æ—¶è¯­éŸ³å®¢æˆ·ç«¯è¿æ¥æˆåŠŸ');
          
        } catch (error) {
          console.error('âŒ å®æ—¶è¯­éŸ³æœåŠ¡åˆå§‹åŒ–å¤±è´¥:', error);
          setConnectionError('å®æ—¶è¯­éŸ³æœåŠ¡åˆå§‹åŒ–å¤±è´¥ï¼š' + error.message);
        }
      };

      initializeRealtime();

      return () => {
        console.log('ğŸ§¹ æ¸…ç†å®æ—¶è¯­éŸ³ç»„ä»¶');
        if (clientRef.current) {
          clientRef.current.disconnect();
        }
        if (wavRecorderRef.current) {
          wavRecorderRef.current.end();
        }
        if (wavPlayerRef.current) {
          wavPlayerRef.current.interrupt();
        }
      };
    }, [sessionId]); // ä¾èµ–sessionId

    const setupEventHandlers = () => {
      const client = clientRef.current;
      
      // è¿æ¥äº‹ä»¶
      client.on('realtime.connecting', () => {
        console.log('ğŸ”„ æ­£åœ¨è¿æ¥åˆ°å®æ—¶è¯­éŸ³API...');
        setConnectionError('');
      });

      client.on('realtime.connected', () => {
        console.log('âœ… å·²è¿æ¥åˆ°å®æ—¶è¯­éŸ³API');
        setIsConnected(true);
        setConnectionError('');
        
        // é€šçŸ¥çˆ¶ç»„ä»¶å®æ—¶è¯­éŸ³å·²å°±ç»ª
        if (onReady) {
          onReady(true);
        }
      });

      client.on('realtime.disconnected', () => {
        console.log('âŒ ä¸å®æ—¶è¯­éŸ³APIæ–­å¼€è¿æ¥');
        setIsConnected(false);
        if (onReady) {
          onReady(false);
        }
      });

      client.on('error', (error) => {
        console.error('âŒ å®æ—¶è¯­éŸ³APIé”™è¯¯:', error);
        setConnectionError('è¿æ¥é”™è¯¯ï¼š' + (error.message || 'æœªçŸ¥é”™è¯¯'));
        if (onReady) {
          onReady(false);
        }
      });

      // å¯¹è¯äº‹ä»¶ - æŒ‰ç…§Step-Realtime-Consoleçš„æ–¹å¼å¤„ç†
      client.on('conversation.updated', async (data) => {
        const { item, delta } = data;
        
        console.log('ğŸ“ å¯¹è¯æ›´æ–°:', { item: item?.id, delta: !!delta });
        
        // å¤„ç†éŸ³é¢‘æ’­æ”¾
        if (delta?.audio) {
          console.log('ğŸ”Š æ¥æ”¶åˆ°AIéŸ³é¢‘æ•°æ®');
          wavPlayerRef.current.add16BitPCM(delta.audio, item.id);
          setIsSpeaking(true);
        }
        
        // å¤„ç†è½¬å½•æ–‡æœ¬
        if (delta?.transcript) {
          console.log('ğŸ“ ç”¨æˆ·è½¬å½•:', delta.transcript);
          onTranscript?.(delta.transcript);
        }
        
        // å¤„ç†å®Œæˆçš„å“åº”
        if (item?.status === 'completed' && item?.role === 'assistant') {
          const transcript = item.formatted?.transcript || item.content?.[0]?.transcript || '';
          console.log('âœ… AIå›å¤å®Œæˆ:', transcript);
          
          if (transcript) {
            onAIResponse?.(transcript);
          }
          setIsProcessing(false);
          setIsSpeaking(false);
        }
      });

      // VADäº‹ä»¶å¤„ç†
      client.on('conversation.interrupted', async () => {
        console.log('â¸ï¸ å¯¹è¯è¢«æ‰“æ–­');
        const trackSampleOffset = await wavPlayerRef.current.interrupt();
        if (trackSampleOffset?.trackId) {
          const { trackId, offset } = trackSampleOffset;
          client.cancelResponse(trackId, offset);
        }
        setIsSpeaking(false);
      });

      // æœåŠ¡å™¨VADäº‹ä»¶
      client.on('server.input_audio_buffer.speech_started', () => {
        console.log('ğŸ¤ æ£€æµ‹åˆ°ç”¨æˆ·å¼€å§‹è¯´è¯');
        setIsRecording(true);
      });

      client.on('server.input_audio_buffer.speech_stopped', () => {
        console.log('ğŸ¤ æ£€æµ‹åˆ°ç”¨æˆ·åœæ­¢è¯´è¯');
        setIsRecording(false);
      });

      // å“åº”å¼€å§‹å’Œç»“æŸ
      client.on('server.response.audio.delta', () => {
        if (!isSpeaking) {
          console.log('ğŸ”Š AIå¼€å§‹æ’­æ”¾éŸ³é¢‘');
          setIsSpeaking(true);
        }
      });

      client.on('server.response.done', () => {
        console.log('âœ… AIå›å¤å®Œæˆ');
        setIsSpeaking(false);
        setIsProcessing(false);
      });
    };

    // è‡ªåŠ¨å¼€å§‹VADå½•éŸ³ï¼ˆå½“è¿æ¥å»ºç«‹åï¼‰
    React.useEffect(() => {
      if (isConnected && clientRef.current && wavRecorderRef.current) {
        const startVADRecording = async () => {
          try {
            console.log('ğŸ¤ å¼€å§‹VADå½•éŸ³æ¨¡å¼');
            
            // ç¡®ä¿ä¼šè¯é…ç½®å·²å‘é€ï¼ˆåç«¯ä¼šè‡ªåŠ¨å‘é€ï¼‰
            // è¿™é‡Œæˆ‘ä»¬å¼€å§‹å½•éŸ³ï¼Œè®©æœåŠ¡å™¨çš„VADæ¥æ£€æµ‹è¯­éŸ³
            await wavRecorderRef.current.record((data) => {
              clientRef.current.appendInputAudio(data.mono);
            });
            
            console.log('âœ… VADå½•éŸ³æ¨¡å¼å·²å¯åŠ¨');
            
          } catch (error) {
            console.error('âŒ å¯åŠ¨VADå½•éŸ³å¤±è´¥:', error);
            setConnectionError('å¯åŠ¨è¯­éŸ³æ£€æµ‹å¤±è´¥ï¼š' + error.message);
          }
        };

        // å»¶è¿Ÿå¯åŠ¨ï¼Œç¡®ä¿è¿æ¥ç¨³å®š
        const timer = setTimeout(startVADRecording, 1000);
        return () => clearTimeout(timer);
      }
    }, [isConnected]);

    // æ‰‹åŠ¨å½•åˆ¶æ§åˆ¶ï¼ˆç”¨äºæµ‹è¯•ï¼‰
    const startRecording = async () => {
      if (!isConnected || !wavRecorderRef.current || !clientRef.current) return;

      try {
        console.log('ğŸ¤ æ‰‹åŠ¨å¼€å§‹å½•åˆ¶');
        setIsRecording(true);
        
        if (wavRecorderRef.current.getStatus() !== 'recording') {
          await wavRecorderRef.current.record((data) => {
            clientRef.current.appendInputAudio(data.mono);
          });
        }
        
      } catch (error) {
        console.error('âŒ æ‰‹åŠ¨å½•åˆ¶å¤±è´¥:', error);
        setConnectionError('å¼€å§‹å½•åˆ¶å¤±è´¥ï¼š' + error.message);
        setIsRecording(false);
      }
    };

    const stopRecording = async () => {
      if (!wavRecorderRef.current || !clientRef.current) return;

      try {
        console.log('ğŸ›‘ æ‰‹åŠ¨åœæ­¢å½•åˆ¶');
        await wavRecorderRef.current.pause();
        clientRef.current.createResponse();
        setIsRecording(false);
        setIsProcessing(true);
      } catch (error) {
        console.error('âŒ åœæ­¢å½•åˆ¶å¤±è´¥:', error);
        setIsRecording(false);
        setIsProcessing(false);
      }
    };

    const getStatusDisplay = () => {
      if (connectionError) {
        return { color: 'text-red-600', bg: 'bg-red-500', text: 'è¿æ¥é”™è¯¯' };
      }
      if (!sessionId) {
        return { color: 'text-gray-500', bg: 'bg-gray-300', text: 'ç­‰å¾…ä¼šè¯ID...' };
      }
      if (isSpeaking) {
        return { color: 'text-blue-600', bg: 'bg-blue-500', text: 'AIæ­£åœ¨å›ç­”...' };
      }
      if (isRecording) {
        return { color: 'text-red-500', bg: 'bg-red-500', text: 'æ­£åœ¨å¬ä½ è¯´è¯...' };
      }
      if (isConnected) {
        return { color: 'text-green-600', bg: 'bg-green-500', text: 'å®æ—¶å¯¹è¯è¿›è¡Œä¸­' };
      }
      return { color: 'text-gray-500', bg: 'bg-gray-300', text: 'æ­£åœ¨è¿æ¥...' };
    };

    const status = getStatusDisplay();

    return (
      <div data-name="realtime-voice-chat" data-file="components/RealtimeVoiceChat.js">
        <div className="py-6">
          <div className="flex items-center justify-center gap-3 mb-4">
            <div className={`w-4 h-4 rounded-full ${status.bg} ${(isRecording || isSpeaking) ? 'animate-pulse' : ''}`}></div>
            <span className={`font-semibold ${status.color}`}>
              {status.text}
            </span>
          </div>
          
          {connectionError && (
            <div className="bg-red-50 rounded-lg p-4 border border-red-200 mb-4">
              <p className="text-sm text-red-600 mb-2">{connectionError}</p>
              <button 
                onClick={() => window.location.reload()}
                className="text-sm bg-red-100 hover:bg-red-200 text-red-700 px-3 py-1 rounded transition-colors"
              >
                é‡æ–°åŠ è½½
              </button>
            </div>
          )}
          
          <div className="text-center">
            <p className="text-sm text-[var(--text-secondary)] mb-2">
              {isConnected 
                ? 'ğŸ¤ å®æ—¶è¯­éŸ³å¯¹è¯è¿›è¡Œä¸­ï¼Œç›´æ¥å¼€å§‹è¯´è¯å³å¯'
                : 'æ­£åœ¨è¿æ¥å®æ—¶è¯­éŸ³æœåŠ¡ï¼Œè¯·ç¨å€™...'
              }
            </p>
            
            {sessionId && (
              <p className="text-xs text-[var(--text-secondary)]">
                ä¼šè¯: {sessionId.substring(0, 8)}...
              </p>
            )}
            
            {isConnected && (
              <div className="mt-3">
                <p className="text-xs text-[var(--text-secondary)]">
                  ğŸ’¡ è¯­éŸ³è‡ªåŠ¨æ£€æµ‹å·²å¯ç”¨ï¼Œæ— éœ€æŒ‰é”®ç›´æ¥è¯´è¯
                </p>
              </div>
            )}
          </div>
          
          {!isConnected && !connectionError && sessionId && (
            <div className="mt-4 text-center">
              <div className="animate-spin rounded-full h-6 w-6 border-b-2 border-[var(--primary-color)] mx-auto mb-2"></div>
              <p className="text-xs text-[var(--text-secondary)]">
                æ­£åœ¨è¿æ¥å®æ—¶è¯­éŸ³æœåŠ¡...
              </p>
            </div>
          )}

          {/* æ‰‹åŠ¨æ§åˆ¶æŒ‰é’®ï¼ˆç”¨äºæµ‹è¯•ï¼‰ */}
          {isConnected && (
            <div className="mt-4 flex justify-center gap-2">
              <button
                onClick={isRecording ? stopRecording : startRecording}
                disabled={isProcessing || isSpeaking}
                className={`px-3 py-1 rounded text-xs font-medium transition-colors ${
                  isRecording 
                    ? 'bg-red-500 hover:bg-red-600 text-white' 
                    : 'bg-green-500 hover:bg-green-600 text-white'
                } disabled:opacity-50 disabled:cursor-not-allowed`}
              >
                {isRecording ? 'åœæ­¢å½•åˆ¶' : 'æ‰‹åŠ¨å½•åˆ¶'}
              </button>
            </div>
          )}

          {/* çŠ¶æ€æŒ‡ç¤ºå™¨ */}
          <div className="mt-4 flex justify-center items-center gap-4 text-xs text-[var(--text-secondary)]">
            <div className={`flex items-center gap-1 ${isConnected ? 'text-green-600' : 'text-gray-400'}`}>
              <div className={`w-2 h-2 rounded-full ${isConnected ? 'bg-green-500' : 'bg-gray-400'}`}></div>
              <span>è¿æ¥</span>
            </div>
            <div className={`flex items-center gap-1 ${isRecording ? 'text-red-600' : 'text-gray-400'}`}>
              <div className={`w-2 h-2 rounded-full ${isRecording ? 'bg-red-500' : 'bg-gray-400'}`}></div>
              <span>å½•éŸ³</span>
            </div>
            <div className={`flex items-center gap-1 ${isSpeaking ? 'text-blue-600' : 'text-gray-400'}`}>
              <div className={`w-2 h-2 rounded-full ${isSpeaking ? 'bg-blue-500' : 'bg-gray-400'}`}></div>
              <span>æ’­æ”¾</span>
            </div>
          </div>
        </div>
      </div>
    );
  } catch (error) {
    console.error('âŒ RealtimeVoiceChatç»„ä»¶é”™è¯¯:', error);
    return (
      <div className="py-6 text-center">
        <div className="bg-red-50 rounded-lg p-4 border border-red-200">
          <p className="text-sm text-red-600">å®æ—¶è¯­éŸ³ç»„ä»¶åŠ è½½å¤±è´¥: {error.message}</p>
          <button 
            onClick={() => window.location.reload()}
            className="mt-2 text-sm bg-red-100 hover:bg-red-200 text-red-700 px-3 py-1 rounded transition-colors"
          >
            é‡æ–°åŠ è½½
          </button>
        </div>
      </div>
    );
  }
}